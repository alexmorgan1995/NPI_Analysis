# FUNCTION COMPUTING Td (method 1)
# Function takes a dataframe as argument, of the form cbind(date, Number of New Cases)
compute.td.m1<- function(dat, user.t1, user.t2){
user.t1<- as.Date(user.t1)
user.t2<- as.Date(user.t2)
dat$cumNewCases<- cumsum(dat[,2])
nb.days<- as.numeric(as.Date(user.t2) - as.Date(user.t1))
user.n.t1<- dat %>% filter(date == user.t1) %>% select(cumNewCases)
user.n.t2<- dat %>% filter(date == user.t2) %>% select(cumNewCases)
Td<- round(nb.days/(log2(user.n.t2[[1]]/user.n.t1[[1]])), 3)
return(Td)
}
# FUNCTION SIMULATING DATASET
# Takes as argument: its = number of datasets to generate
# df = dataframe of the form (date, numNewCases)
sim.epi<- function(df, its){
# FORMAT DATA< GET CUMULATIVE INCIDENCE
df0 <- df %>% filter(cumNumCases > 0) # trim data to first reported case
# MODIF TO MAKE:
df0$numNewCases<- c(df0$cumNumCases[1], diff(df0$cumNumCases)) # TO CHECK
#df0$numNewCases<- c(1, diff(df0$cumNumCases)) # TO CHECK
df0$date<- as.Date(df0$date)
df0$day_since_start<- c(0, cumsum(as.numeric(diff(df0$date)))) # Get date in terms of "day first case"
df0$cumIncidence<- cumsum(df0$numNewCases) # TO CHECK
# SIMULATE DATASETS
# Each timepoint, draw a number of new cases from a poisson distribution of mean the number of new reported cases for that day in the observed data.
# Directly append the simulated data to dataframe for easier plotting after
df0<- cbind(df0, as.data.frame(matrix(NA, nrow = nrow(df0), ncol = its)))
for(j in 1:length(df0$numNewCases)){ # TO CHECK: this to be modified if we decide on computing mu exclding very early phase
df0[j,which(substr(colnames(df0), 1, 1) == "V")]<- rpois(n = its, lambda = df0$numNewCases[j])
}
return(df0)
}
drop_auth(rdstoken = 'tokenfile.RDS')
# If app run after before 14h, report of 'today' not there yet, so fetches report of today - 1
latest<- as.character(Sys.Date()-1)
# Dropbox: gmail account: dailyscraperbox@gmail.com, pw: dsbcid19! (same pw for gmail account and dropbox)
# The RDS file above should allow you to connect to the dropbox
# Giles python script must forward those files to that dropbox then
drop_download(paste0('/Applications/COVID_Scraper/Daily_scraper_reports/SARS-Cov-2-Scotland-', latest, '_raw.xlsx'), overwrite = TRUE)
d <- read_excel(paste0('SARS-Cov-2-Scotland-', latest, '_raw.xlsx'))
d[1, 2] <- "Ayrshire"
d[13, 2] <- "Scotland"
d2<- as.data.frame(
d %>%
filter(Health_Board == input$healthboard) %>% # Get correct row
select(-c(1,2, ncol(d)-1, ncol(d))))
colnames(d2)[ncol(d2)]<- (latest) # latest day does not have a colname
d2<- d2 %>%
gather('date', 'cumNumCases', 1:ncol(d2)) %>%
mutate(region = input$healthboard) %>% # Needed for plotting with ggplot
arrange(date)
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
# SIMULATE DATA
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
# TEXTBOX OUTPUT
tds.ci<- round(CI(Tds, ci = 0.95), 3)
paste0('For the region: ', user.input.region,", between ", t1, " and ", t2)
paste0("The doubling time is: ", td.obs, " (", tds.ci['lower'] , ' - ', tds.ci['upper'] , ")")
library(readxl); library(ggplot2); library(dplyr); library(tidyr); library(rdrop2); library(Rmisc); library(lubridate);library("shiny"); library("rsconnect")
# FUNCTION COMPUTING Td (method 1)
# Function takes a dataframe as argument, of the form cbind(date, Number of New Cases)
compute.td.m1<- function(dat, user.t1, user.t2){
user.t1<- as.Date(user.t1)
user.t2<- as.Date(user.t2)
dat$cumNewCases<- cumsum(dat[,2])
nb.days<- as.numeric(as.Date(user.t2) - as.Date(user.t1))
user.n.t1<- dat %>% filter(date == user.t1) %>% select(cumNewCases)
user.n.t2<- dat %>% filter(date == user.t2) %>% select(cumNewCases)
Td<- round(nb.days/(log2(user.n.t2[[1]]/user.n.t1[[1]])), 3)
return(Td)
}
# FUNCTION SIMULATING DATASET
# Takes as argument: its = number of datasets to generate
# df = dataframe of the form (date, numNewCases)
sim.epi<- function(df, its){
# FORMAT DATA< GET CUMULATIVE INCIDENCE
df0 <- df %>% filter(cumNumCases > 0) # trim data to first reported case
# MODIF TO MAKE:
df0$numNewCases<- c(df0$cumNumCases[1], diff(df0$cumNumCases)) # TO CHECK
#df0$numNewCases<- c(1, diff(df0$cumNumCases)) # TO CHECK
df0$date<- as.Date(df0$date)
df0$day_since_start<- c(0, cumsum(as.numeric(diff(df0$date)))) # Get date in terms of "day first case"
df0$cumIncidence<- cumsum(df0$numNewCases) # TO CHECK
# SIMULATE DATASETS
# Each timepoint, draw a number of new cases from a poisson distribution of mean the number of new reported cases for that day in the observed data.
# Directly append the simulated data to dataframe for easier plotting after
df0<- cbind(df0, as.data.frame(matrix(NA, nrow = nrow(df0), ncol = its)))
for(j in 1:length(df0$numNewCases)){ # TO CHECK: this to be modified if we decide on computing mu exclding very early phase
df0[j,which(substr(colnames(df0), 1, 1) == "V")]<- rpois(n = its, lambda = df0$numNewCases[j])
}
return(df0)
}
drop_auth(rdstoken = 'tokenfile.RDS')
# If app run after before 14h, report of 'today' not there yet, so fetches report of today - 1
latest<- as.character(Sys.Date()-1)
# Dropbox: gmail account: dailyscraperbox@gmail.com, pw: dsbcid19! (same pw for gmail account and dropbox)
# The RDS file above should allow you to connect to the dropbox
# Giles python script must forward those files to that dropbox then
drop_download(paste0('/Applications/COVID_Scraper/Daily_scraper_reports/SARS-Cov-2-Scotland-', latest, '_raw.xlsx'), overwrite = TRUE)
d <- read_excel(paste0('SARS-Cov-2-Scotland-', latest, '_raw.xlsx'))
d[1, 2] <- "Ayrshire"
d[13, 2] <- "Scotland"
d2<- as.data.frame(
d %>%
filter(Health_Board == input$healthboard) %>% # Get correct row
select(-c(1,2, ncol(d)-1, ncol(d))))
colnames(d2)[ncol(d2)]<- (latest) # latest day does not have a colname
d2<- d2 %>%
gather('date', 'cumNumCases', 1:ncol(d2)) %>%
mutate(region = input$healthboard) %>% # Needed for plotting with ggplot
arrange(date)
input$healthboard <- "Lothian"
input <- dataframe()
input <- data_frame()
input <- data.frame()
input$healthboard <- "Lothian"
input <- data.frame("healthboard" = "Lothian")
d2<- as.data.frame(
d %>%
filter(Health_Board == input$healthboard) %>% # Get correct row
select(-c(1,2, ncol(d)-1, ncol(d))))
colnames(d2)[ncol(d2)]<- (latest) # latest day does not have a colname
d2<- d2 %>%
gather('date', 'cumNumCases', 1:ncol(d2)) %>%
mutate(region = input$healthboard) %>% # Needed for plotting with ggplot
arrange(date)
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
t1 <"2020-03-06"
t1 <"2020-03-20"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
# SIMULATE DATA
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
# TEXTBOX OUTPUT
tds.ci<- round(CI(Tds, ci = 0.95), 3)
paste0('For the region: ', user.input.region,", between ", t1, " and ", t2)
paste0("The doubling time is: ", td.obs, " (", tds.ci['lower'] , ' - ', tds.ci['upper'] , ")")
t1 <- "2020-03-06"
t1 <- "2020-03-20"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
t1 <- "2020-03-06"
t2 <- "2020-03-20"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
user.input.region <-"Lothian"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
# SIMULATE DATA
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
# TEXTBOX OUTPUT
tds.ci<- round(CI(Tds, ci = 0.95), 3)
paste0('For the region: ', user.input.region,", between ", t1, " and ", t2)
paste0("The doubling time is: ", td.obs, " (", tds.ci['lower'] , ' - ', tds.ci['upper'] , ")")
compute.mu.m1<- function(dat, user.t1, user.t2){
user.t1<- as.Date(user.t1)
user.t2<- as.Date(user.t2)
dat$cumNewCases<- cumsum(dat[,2])
nb.days<- as.numeric(as.Date(user.t2) - as.Date(user.t1))
user.n.t1<- dat %>% filter(date == user.t1) %>% select(cumNewCases)
user.n.t2<- dat %>% filter(date == user.t2) %>% select(cumNewCases)
Td<- round(nb.days/(log2(user.n.t2[[1]]/user.n.t1[[1]])), 3)
return(Td)
}
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
# TEXTBOX OUTPUT
tds.ci<- round(CI(Tds, ci = 0.95), 3)
paste0('For the region: ', user.input.region,", between ", t1, " and ", t2)
paste0("The doubling time is: ", td.obs, " (", tds.ci['lower'] , ' - ', tds.ci['upper'] , ")")
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
selectInput("healthboard", "Scottish Health Board", c("Scotland" = "Scotland",
"Lothian" = "Lothian",
"Lanarkshire" = "Lanarkshire",
"Forth Valley" = "Forth Valley",
"Fife" = "Fife",
"Greater Glasgow and Clyde" = "Greater Glasgow and Clyde"
))
rsconnect::setAccountInfo(name='alexmorgan1995', token='DD49CDC77B3774F7947E4DBB0BBA525E', secret='dDU1+d6VAa5xueXTV8hySEyB0fGtU5PdsA3aH8Gt')
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
deployApp()
rsconnect::setAccountInfo(name='alexmorgan1995', token='B39666E8958C7567AD3F21F91A249496', secret='DwImkCjNPP+Q6/XkLQWovP8P1mzGJXFEGnEm1R2p')
deployApp()
rsconnect::setAccountInfo(name='alexmorgan1995', token='DD49CDC77B3774F7947E4DBB0BBA525E', secret='dDU1+d6VAa5xueXTV8hySEyB0fGtU5PdsA3aH8Gt')
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
deployApp()
deployApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
as.Date("2009-10-01")-7
"2020-03-07"-7
as.Date("2020-03-07")-7
as.Date("2020-03-08")-7
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
deployApp()
deployApp()
?multisolve
??multisolve
?desolve
??desolve
deployApp()
library(readxl); library(ggplot2); library(dplyr); library(tidyr); library(rdrop2); library(Rmisc); library(lubridate);library("shiny"); library("rsconnect")
# FUNCTION COMPUTING Td (method 1)
# Function takes a dataframe as argument, of the form cbind(date, Number of New Cases)
compute.mu.m1<- function(dat, user.t1, user.t2){
user.t1<- as.Date(user.t1)
user.t2<- as.Date(user.t2)
dat$cumNewCases<- cumsum(dat[,2])
nb.days<- as.numeric(as.Date(user.t2) - as.Date(user.t1))
user.n.t1<- dat %>% filter(date == user.t1) %>% select(cumNewCases)
user.n.t2<- dat %>% filter(date == user.t2) %>% select(cumNewCases)
Td<- round(nb.days/(log2(user.n.t2[[1]]/user.n.t1[[1]])), 3)
return(Td)
}
# FUNCTION SIMULATING DATASET
# Takes as argument: its = number of datasets to generate
# df = dataframe of the form (date, numNewCases)
sim.epi<- function(df, its){
# FORMAT DATA< GET CUMULATIVE INCIDENCE
df0 <- df %>% filter(cumNumCases > 0) # trim data to first reported case
# MODIF TO MAKE:
df0$numNewCases<- c(df0$cumNumCases[1], diff(df0$cumNumCases)) # TO CHECK
#df0$numNewCases<- c(1, diff(df0$cumNumCases)) # TO CHECK
df0$date<- as.Date(df0$date)
df0$day_since_start<- c(0, cumsum(as.numeric(diff(df0$date)))) # Get date in terms of "day first case"
df0$cumIncidence<- cumsum(df0$numNewCases) # TO CHECK
# SIMULATE DATASETS
# Each timepoint, draw a number of new cases from a poisson distribution of mean the number of new reported cases for that day in the observed data.
# Directly append the simulated data to dataframe for easier plotting after
df0<- cbind(df0, as.data.frame(matrix(NA, nrow = nrow(df0), ncol = its)))
for(j in 1:length(df0$numNewCases)){ # TO CHECK: this to be modified if we decide on computing mu exclding very early phase
df0[j,which(substr(colnames(df0), 1, 1) == "V")]<- rpois(n = its, lambda = df0$numNewCases[j])
}
return(df0)
}
drop_auth(rdstoken = 'tokenfile.RDS')
# If app run after before 14h, report of 'today' not there yet, so fetches report of today - 1
latest<- as.character(Sys.Date()-1)
# Dropbox: gmail account: dailyscraperbox@gmail.com, pw: dsbcid19! (same pw for gmail account and dropbox)
# The RDS file above should allow you to connect to the dropbox
# Giles python script must forward those files to that dropbox then
drop_download(paste0('/Applications/COVID_Scraper/Daily_scraper_reports/SARS-Cov-2-Scotland-', latest, '_raw.xlsx'), overwrite = TRUE)
d <- read_excel(paste0('SARS-Cov-2-Scotland-', latest, '_raw.xlsx'))
d[1, 2] <- "Ayrshire"
d[13, 2] <- "Scotland"
input <- data.frame("healthboard" = "Lothian")
user.input.region <-"Lothian"
d2<- as.data.frame(
d %>%
filter(Health_Board == input$healthboard) %>% # Get correct row
select(-c(1,2, ncol(d)-1, ncol(d))))
colnames(d2)[ncol(d2)]<- (latest) # latest day does not have a colname
d2<- d2 %>%
gather('date', 'cumNumCases', 1:ncol(d2)) %>%
mutate(region = input$healthboard) %>% # Needed for plotting with ggplot
arrange(date)
t1 <- "2020-03-06"
t2 <- "2020-03-20"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
# SIMULATE DATA
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
alpha = 0.1
ci.low.basic<- round((2*HM.Tds.obs) - quantile(HM.Tds.sim.store, probs = c(1 - (alpha/2)))[[1]], 3)
ci.upp.basic<- round((2*HM.Tds.obs) - quantile(HM.Tds.sim.store, probs = c(alpha/2))[[1]], 3)
HM.Tds.sim.store
tds.ci<- round(CI(Tds, ci = 0.95), 3)
library(readxl); library(ggplot2); library(dplyr); library(tidyr); library(rdrop2); library(Rmisc); library(lubridate);library("shiny"); library("rsconnect")
# FUNCTION COMPUTING Td (method 1)
# Function takes a dataframe as argument, of the form cbind(date, Number of New Cases)
compute.mu.m1<- function(dat, user.t1, user.t2){
user.t1<- as.Date(user.t1)
user.t2<- as.Date(user.t2)
dat$cumNewCases<- cumsum(dat[,2])
nb.days<- as.numeric(as.Date(user.t2) - as.Date(user.t1))
user.n.t1<- dat %>% filter(date == user.t1) %>% select(cumNewCases)
user.n.t2<- dat %>% filter(date == user.t2) %>% select(cumNewCases)
Td<- round(nb.days/(log2(user.n.t2[[1]]/user.n.t1[[1]])), 3)
return(Td)
}
# FUNCTION SIMULATING DATASET
# Takes as argument: its = number of datasets to generate
# df = dataframe of the form (date, numNewCases)
sim.epi<- function(df, its){
# FORMAT DATA< GET CUMULATIVE INCIDENCE
df0 <- df %>% filter(cumNumCases > 0) # trim data to first reported case
# MODIF TO MAKE:
df0$numNewCases<- c(df0$cumNumCases[1], diff(df0$cumNumCases)) # TO CHECK
#df0$numNewCases<- c(1, diff(df0$cumNumCases)) # TO CHECK
df0$date<- as.Date(df0$date)
df0$day_since_start<- c(0, cumsum(as.numeric(diff(df0$date)))) # Get date in terms of "day first case"
df0$cumIncidence<- cumsum(df0$numNewCases) # TO CHECK
# SIMULATE DATASETS
# Each timepoint, draw a number of new cases from a poisson distribution of mean the number of new reported cases for that day in the observed data.
# Directly append the simulated data to dataframe for easier plotting after
df0<- cbind(df0, as.data.frame(matrix(NA, nrow = nrow(df0), ncol = its)))
for(j in 1:length(df0$numNewCases)){ # TO CHECK: this to be modified if we decide on computing mu exclding very early phase
df0[j,which(substr(colnames(df0), 1, 1) == "V")]<- rpois(n = its, lambda = df0$numNewCases[j])
}
return(df0)
}
drop_auth(rdstoken = 'tokenfile.RDS')
# If app run after before 14h, report of 'today' not there yet, so fetches report of today - 1
latest<- as.character(Sys.Date()-1)
# Dropbox: gmail account: dailyscraperbox@gmail.com, pw: dsbcid19! (same pw for gmail account and dropbox)
# The RDS file above should allow you to connect to the dropbox
# Giles python script must forward those files to that dropbox then
drop_download(paste0('/Applications/COVID_Scraper/Daily_scraper_reports/SARS-Cov-2-Scotland-', latest, '_raw.xlsx'), overwrite = TRUE)
d <- read_excel(paste0('SARS-Cov-2-Scotland-', latest, '_raw.xlsx'))
d[1, 2] <- "Ayrshire"
d[13, 2] <- "Scotland"
input <- data.frame("healthboard" = "Lothian")
user.input.region <-"Lothian"
d2<- as.data.frame(
d %>%
filter(Health_Board == input$healthboard) %>% # Get correct row
select(-c(1,2, ncol(d)-1, ncol(d))))
colnames(d2)[ncol(d2)]<- (latest) # latest day does not have a colname
d2<- d2 %>%
gather('date', 'cumNumCases', 1:ncol(d2)) %>%
mutate(region = input$healthboard) %>% # Needed for plotting with ggplot
arrange(date)
t1 <- "2020-03-06"
t2 <- "2020-03-20"
# APPLY FUNCTION TO COMPUTE TD OVER OBSERVED DATASET
d2.2<- d2 %>%
mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
select(date, numNewCases)
td.obs<- compute.td.m1(d2.2, user.t1 = t1, user.t2 = t2)
paste0("Doubling time: ", td.obs, ' for ', user.input.region," between ", t1, " and ", t2)
# SIMULATE DATA
d2.3<- sim.epi(d2, 1000)
Tds<- NULL
sim.indices<- which(substr(colnames(d2.3), 1, 1) == 'V') # Get indices of columns corresponding to simulated datasets
for(i in 1:length(sim.indices)){
Tds<- c(Tds, compute.mu.m1(d2.3[,c(1,sim.indices[i])], user.t1 = t1, user.t2 = t2))
}
alpha = 0.1
ci.low.basic <- round((2*td.obs) - quantile(Tds, probs = c(1 - (alpha/2)))[[1]], 3)
ci.upp.basic <- round((2*td.obs) - quantile(Tds, probs = c(alpha/2))[[1]], 3)
# TEXTBOX OUTPUT
tds.ci<- round(CI(Tds, ci = 0.95), 3)
paste0('For the region: ', user.input.region,", between ", t1, " and ", t2)
paste0("The doubling time is: ", td.obs, " (", ci.low.basic , ' - ', ci.upp.basic  , ")")
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
deployApp()
deployApp()
deployApp()
rsconnect::setAccountInfo(name='epigroup', token='F535780FD28D69985D2134C7DFF7D95B', secret='X0RMZMzB83BlCKnQLMJ5PbLgi45E4kWLSAT4k5jy')
library(rsconnect); library("shiny");
setwd("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
runApp()
deployApp()
rsconnect::setAccountInfo(name='epigroup', token='F535780FD28D69985D2134C7DFF7D95B', secret='X0RMZMzB83BlCKnQLMJ5PbLgi45E4kWLSAT4k5jy')
library(rsconnect)
rsconnect::deployApp("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
rsconnect::deployApp("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time_v1_v1")
library(rsconnect)
rsconnect::deployApp("C:/Users/amorg/Documents/PhD/nCoV Work/Models/Shiny_App/Dbl_Time")
